import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# Page configuration
st.set_page_config(
    page_title="Strava Analytics Dashboard",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
    }
    .stMetric {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    </style>
    """, unsafe_allow_html=True)

# ============================================================================
# DATA LOADING AND PREPROCESSING
# ============================================================================

@st.cache_data
def load_and_process_data(file_path):
    """Load and preprocess Strava data"""
    # Read data
    df = pd.read_csv(file_path)
    
    # Convert dates
    df['start_date'] = pd.to_datetime(df['start_date'])
    df['start_date_local'] = pd.to_datetime(df['start_date_local'])
    
    # Distance conversions
    df['distance_km'] = df['distance'] / 1000
    df['distance_miles'] = df['distance'] / 1609.34
    
    # Time conversions
    df['moving_time_min'] = df['moving_time'] / 60
    df['moving_time_hr'] = df['moving_time'] / 3600
    df['elapsed_time_min'] = df['elapsed_time'] / 60
    
    # Pace calculations
    df['pace_min_per_km'] = np.where(
        df['distance_km'] > 0,
        df['moving_time_min'] / df['distance_km'],
        np.nan
    )
    df['pace_min_per_mile'] = np.where(
        df['distance_miles'] > 0,
        df['moving_time_min'] / df['distance_miles'],
        np.nan
    )
    
    # Speed conversion
    df['speed_kmh'] = df['average_speed'] * 3.6
    df['max_speed_kmh'] = df['max_speed'] * 3.6
    
    # Temporal features
    df['year'] = df['start_date_local'].dt.year
    df['month'] = df['start_date_local'].dt.month
    df['day_of_week'] = df['start_date_local'].dt.dayofweek
    df['day_name'] = df['start_date_local'].dt.day_name()
    df['hour'] = df['start_date_local'].dt.hour
    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
    
    # Time of day
    def categorize_time(hour):
        if 5 <= hour < 12:
            return 'Morning'
        elif 12 <= hour < 17:
            return 'Afternoon'
        elif 17 <= hour < 21:
            return 'Evening'
        else:
            return 'Night'
    
    df['time_of_day'] = df['hour'].apply(categorize_time)
    
    # Fill categorical NaNs
    if 'trainer' in df.columns:
        df['trainer'] = df['trainer'].fillna(False)
    if 'commute' in df.columns:
        df['commute'] = df['commute'].fillna(False)
    
    return df

# Load data
DATA_PATH = 'Strava Workouts - All - Sheet1.csv'  # Update this path as needed

try:
    data = load_and_process_data(DATA_PATH)
    data_loaded = True
except Exception as e:
    st.error(f"Error loading data: {e}")
    st.info("Please update the DATA_PATH variable in the code to point to your CSV file.")
    data_loaded = False
    st.stop()

# ============================================================================
# SIDEBAR - NAVIGATION AND FILTERS
# ============================================================================

st.sidebar.title("ðŸƒ Strava Analytics")
st.sidebar.markdown("---")

# Navigation
page = st.sidebar.radio(
    "Navigation",
    ["Overview", "Lifting Analysis", "Running Analysis", "Performance Patterns"]
)

st.sidebar.markdown("---")
st.sidebar.subheader("Filters")

# Date range filter
min_date = data['start_date_local'].min().date()
max_date = data['start_date_local'].max().date()

date_range = st.sidebar.date_input(
    "Date Range",
    value=(min_date, max_date),
    min_value=min_date,
    max_value=max_date
)

# Sport type filter
sport_types = ['All'] + sorted(data['sport_type'].unique().tolist())
selected_sports = st.sidebar.multiselect(
    "Sport Type",
    options=sport_types,
    default=['All']
)

# Performance threshold (for clustering page)
if page == "Performance Patterns":
    top_performance_pct = st.sidebar.slider(
        "Top Performance Threshold (%)",
        min_value=10,
        max_value=40,
        value=25,
        step=5,
        help="Define what percentage of runs are considered 'top performances'"
    )
    
    lookback_days = st.sidebar.slider(
        "Training Context Window (days)",
        min_value=3,
        max_value=14,
        value=7,
        step=1,
        help="How many days to look back when analyzing training patterns"
    )

st.sidebar.markdown("---")
st.sidebar.info("ðŸ’¡ Use filters to focus on specific time periods or activities")

# Apply filters
filtered_data = data.copy()

# Date filter
if len(date_range) == 2:
    start_date, end_date = date_range
    filtered_data = filtered_data[
        (filtered_data['start_date_local'].dt.date >= start_date) &
        (filtered_data['start_date_local'].dt.date <= end_date)
    ]

# Sport filter
if 'All' not in selected_sports and len(selected_sports) > 0:
    filtered_data = filtered_data[filtered_data['sport_type'].isin(selected_sports)]

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def create_metric_cards(df):
    """Create summary metric cards"""
    col1, col2, col3, col4, col5 = st.columns(5)
    
    # Total workouts
    with col1:
        total_workouts = len(df)
        st.metric("Total Workouts", f"{total_workouts:,}")
    
    # Total distance
    with col2:
        total_miles = df['distance_miles'].sum()
        st.metric("Total Miles", f"{total_miles:.1f}")
    
    # Total time
    with col3:
        total_hours = df['moving_time_hr'].sum()
        st.metric("Total Hours", f"{total_hours:.1f}")
    
    # Runs
    with col4:
        total_runs = len(df[df['sport_type'] == 'Run'])
        avg_pace = df[df['sport_type'] == 'Run']['pace_min_per_mile'].mean()
        st.metric("Total Runs", f"{total_runs:,}", 
                 delta=f"{avg_pace:.2f} min/mi avg" if not np.isnan(avg_pace) else None)
    
    # Lifting
    with col5:
        total_lifting = len(df[df['sport_type'] == 'WeightTraining'])
        avg_duration = df[df['sport_type'] == 'WeightTraining']['moving_time_min'].mean()
        st.metric("Total Lifts", f"{total_lifting:,}",
                 delta=f"{avg_duration:.0f} min avg" if not np.isnan(avg_duration) else None)

def create_sport_breakdown_metrics(df, sport_type):
    """Create detailed metrics for a specific sport"""
    sport_df = df[df['sport_type'] == sport_type]
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        count = len(sport_df)
        st.metric("Total Workouts", f"{count:,}")
    
    with col2:
        if sport_type == 'Run':
            total_dist = sport_df['distance_miles'].sum()
            st.metric("Total Distance", f"{total_dist:.1f} mi")
        else:
            total_time = sport_df['moving_time_hr'].sum()
            st.metric("Total Time", f"{total_time:.1f} hrs")
    
    with col3:
        avg_duration = sport_df['moving_time_min'].mean()
        st.metric("Avg Duration", f"{avg_duration:.0f} min")
    
    with col4:
        if sport_type == 'Run':
            avg_pace = sport_df['pace_min_per_mile'].mean()
            st.metric("Avg Pace", f"{avg_pace:.2f} min/mi")
        else:
            per_week = len(sport_df) / ((sport_df['start_date_local'].max() - sport_df['start_date_local'].min()).days / 7)
            st.metric("Per Week", f"{per_week:.1f}")

# ============================================================================
# PAGE: OVERVIEW
# ============================================================================

if page == "Overview":
    st.title("Training Overview")
    st.markdown("---")
    
    # Summary metrics
    create_metric_cards(filtered_data)
    
    st.markdown("---")
    
    # Two columns for charts
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Workout Distribution")
        workout_counts = filtered_data['sport_type'].value_counts()
        fig = px.pie(
            values=workout_counts.values,
            names=workout_counts.index,
            title="Workouts by Type",
            hole=0.4
        )
        fig.update_traces(textposition='inside', textinfo='percent+label')
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("Activity Over Time")
        monthly_data = filtered_data.groupby(filtered_data['start_date_local'].dt.to_period('M')).size()
        monthly_data.index = monthly_data.index.to_timestamp()
        fig = px.line(
            x=monthly_data.index,
            y=monthly_data.values,
            title="Monthly Workout Count",
            labels={'x': 'Month', 'y': 'Workouts'}
        )
        fig.update_traces(line_color='#1f77b4', line_width=3)
        st.plotly_chart(fig, use_container_width=True)
    
    # Full width chart
    st.subheader("Training Volume by Sport")
    
    # Calculate weekly volumes
    filtered_data['week'] = filtered_data['start_date_local'].dt.to_period('W').dt.to_timestamp()
    weekly_by_sport = filtered_data.groupby(['week', 'sport_type']).size().reset_index(name='count')
    
    fig = px.bar(
        weekly_by_sport,
        x='week',
        y='count',
        color='sport_type',
        title="Weekly Workout Count by Sport Type",
        labels={'week': 'Week', 'count': 'Workouts', 'sport_type': 'Sport'},
        barmode='stack'
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # Day of week heatmap
    st.subheader("Weekly Training Pattern")
    dow_hour = filtered_data.groupby(['day_name', 'hour']).size().reset_index(name='count')
    dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    
    pivot_data = dow_hour.pivot(index='day_name', columns='hour', values='count').fillna(0)
    pivot_data = pivot_data.reindex(dow_order)
    
    fig = px.imshow(
        pivot_data,
        labels=dict(x="Hour of Day", y="Day of Week", color="Workouts"),
        x=pivot_data.columns,
        y=pivot_data.index,
        title="Workout Frequency Heatmap",
        color_continuous_scale='YlOrRd'
    )
    st.plotly_chart(fig, use_container_width=True)

# ============================================================================
# PAGE: LIFTING ANALYSIS
# ============================================================================

elif page == "Lifting Analysis":
    st.title("Lifting Trends Analysis")
    st.markdown("---")
    
    lifting_data = filtered_data[filtered_data['sport_type'] == 'WeightTraining'].copy()
    
    if len(lifting_data) == 0:
        st.warning("No lifting data found in the selected date range.")
    else:
        # Metrics
        create_sport_breakdown_metrics(filtered_data, 'WeightTraining')
        
        st.markdown("---")
        
        # Charts
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Monthly Lifting Volume")
            lifting_data['year_month'] = lifting_data['start_date_local'].dt.to_period('M').dt.to_timestamp()
            monthly_counts = lifting_data.groupby('year_month').size()
            
            fig = px.bar(
                x=monthly_counts.index,
                y=monthly_counts.values,
                title="Lifting Sessions per Month",
                labels={'x': 'Month', 'y': 'Sessions'}
            )
            fig.update_traces(marker_color='steelblue')
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("Day of Week Pattern")
            dow_counts = lifting_data['day_name'].value_counts()
            dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
            dow_counts = dow_counts.reindex(dow_order, fill_value=0)
            
            fig = px.bar(
                x=dow_counts.index,
                y=dow_counts.values,
                title="Lifting by Day of Week",
                labels={'x': 'Day', 'y': 'Sessions'}
            )
            fig.update_traces(marker_color='coral')
            st.plotly_chart(fig, use_container_width=True)
        
        # Duration analysis
        st.subheader("Workout Duration Trends")
        
        lifting_sorted = lifting_data.sort_values('start_date_local')
        lifting_sorted['rolling_avg'] = lifting_sorted['moving_time_min'].rolling(window=5, min_periods=1).mean()
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=lifting_sorted['start_date_local'],
            y=lifting_sorted['moving_time_min'],
            mode='markers',
            name='Individual Workouts',
            marker=dict(size=8, opacity=0.4)
        ))
        fig.add_trace(go.Scatter(
            x=lifting_sorted['start_date_local'],
            y=lifting_sorted['rolling_avg'],
            mode='lines',
            name='5-Workout Rolling Average',
            line=dict(color='red', width=3)
        ))
        fig.update_layout(
            title="Workout Duration Over Time",
            xaxis_title="Date",
            yaxis_title="Duration (minutes)",
            hovermode='x unified'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Consistency metrics
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Time of Day Preference")
            time_counts = lifting_data['time_of_day'].value_counts()
            fig = px.pie(
                values=time_counts.values,
                names=time_counts.index,
                title="Lifting Sessions by Time of Day"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("Consistency Analysis")
            lifting_sorted['days_between'] = lifting_sorted['start_date_local'].diff().dt.days
            
            fig = px.histogram(
                lifting_sorted,
                x='days_between',
                title="Days Between Lifting Sessions",
                labels={'days_between': 'Days', 'count': 'Frequency'},
                nbins=20
            )
            avg_gap = lifting_sorted['days_between'].mean()
            fig.add_vline(x=avg_gap, line_dash="dash", line_color="red",
                         annotation_text=f"Avg: {avg_gap:.1f} days")
            st.plotly_chart(fig, use_container_width=True)
        
        # Key insights
        st.markdown("---")
        st.subheader("Key Insights")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            most_common_day = dow_counts.idxmax()
            st.info(f"**Most Common Training Day:** {most_common_day} ({dow_counts.max()} sessions)")
        
        with col2:
            avg_per_week = len(lifting_data) / ((lifting_data['start_date_local'].max() - lifting_data['start_date_local'].min()).days / 7)
            st.info(f"**Average Frequency:** {avg_per_week:.1f} sessions per week")
        
        with col3:
            avg_duration = lifting_data['moving_time_min'].mean()
            st.info(f"**Average Duration:** {avg_duration:.0f} minutes")

# ============================================================================
# PAGE: RUNNING ANALYSIS
# ============================================================================

elif page == "Running Analysis":
    st.title("Running Trends Analysis")
    st.markdown("---")
    
    running_data = filtered_data[filtered_data['sport_type'] == 'Run'].copy()
    
    if len(running_data) == 0:
        st.warning("No running data found in the selected date range.")
    else:
        # Metrics
        create_sport_breakdown_metrics(filtered_data, 'Run')
        
        st.markdown("---")
        
        # Volume charts
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Monthly Running Distance")
            running_data['year_month'] = running_data['start_date_local'].dt.to_period('M').dt.to_timestamp()
            monthly_miles = running_data.groupby('year_month')['distance_miles'].sum()
            
            fig = px.bar(
                x=monthly_miles.index,
                y=monthly_miles.values,
                title="Monthly Mileage",
                labels={'x': 'Month', 'y': 'Miles'}
            )
            fig.update_traces(marker_color='steelblue')
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("Weekly Mileage Trend")
            running_data['week'] = running_data['start_date_local'].dt.to_period('W').dt.to_timestamp()
            weekly_miles = running_data.groupby('week')['distance_miles'].sum()
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=weekly_miles.index,
                y=weekly_miles.values,
                mode='lines',
                name='Weekly Miles',
                line=dict(color='navy', width=2)
            ))
            fig.add_hline(y=weekly_miles.mean(), line_dash="dash", line_color="red",
                         annotation_text=f"Avg: {weekly_miles.mean():.1f} mi")
            fig.update_layout(
                title="Weekly Mileage Over Time",
                xaxis_title="Week",
                yaxis_title="Miles"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Pace analysis
        st.subheader("Pace Analysis")
        
        running_sorted = running_data.sort_values('start_date_local')
        running_sorted['pace_rolling'] = running_sorted['pace_min_per_mile'].rolling(window=5, min_periods=1).mean()
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=running_sorted['start_date_local'],
            y=running_sorted['pace_min_per_mile'],
            mode='markers',
            name='Individual Runs',
            marker=dict(size=8, opacity=0.4)
        ))
        fig.add_trace(go.Scatter(
            x=running_sorted['start_date_local'],
            y=running_sorted['pace_rolling'],
            mode='lines',
            name='5-Run Rolling Average',
            line=dict(color='red', width=3)
        ))
        fig.update_layout(
            title="Pace Over Time",
            xaxis_title="Date",
            yaxis_title="Pace (min/mile)",
            yaxis=dict(autorange="reversed"),
            hovermode='x unified'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # More charts
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Distance Distribution")
            fig = px.histogram(
                running_data,
                x='distance_miles',
                title="Run Distance Distribution",
                labels={'distance_miles': 'Distance (miles)', 'count': 'Frequency'},
                nbins=20
            )
            avg_dist = running_data['distance_miles'].mean()
            fig.add_vline(x=avg_dist, line_dash="dash", line_color="red",
                         annotation_text=f"Avg: {avg_dist:.2f} mi")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("Pace Distribution")
            fig = px.histogram(
                running_data.dropna(subset=['pace_min_per_mile']),
                x='pace_min_per_mile',
                title="Pace Distribution",
                labels={'pace_min_per_mile': 'Pace (min/mile)', 'count': 'Frequency'},
                nbins=20
            )
            avg_pace = running_data['pace_min_per_mile'].mean()
            fig.add_vline(x=avg_pace, line_dash="dash", line_color="red",
                         annotation_text=f"Avg: {avg_pace:.2f}")
            st.plotly_chart(fig, use_container_width=True)
        
        # Distance vs Pace
        st.subheader("Distance vs Pace Relationship")
        fig = px.scatter(
            running_data,
            x='distance_miles',
            y='pace_min_per_mile',
            title="How Pace Changes with Distance",
            labels={'distance_miles': 'Distance (miles)', 'pace_min_per_mile': 'Pace (min/mile)'},
            trendline="lowess",
            opacity=0.6
        )
        fig.update_layout(yaxis=dict(autorange="reversed"))
        st.plotly_chart(fig, use_container_width=True)
        
        # Day of week pattern
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Running Days")
            dow_counts = running_data['day_name'].value_counts()
            dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
            dow_counts = dow_counts.reindex(dow_order, fill_value=0)
            
            fig = px.bar(
                x=dow_counts.index,
                y=dow_counts.values,
                title="Runs by Day of Week",
                labels={'x': 'Day', 'y': 'Runs'}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("Average Distance by Day")
            dow_dist = running_data.groupby('day_name')['distance_miles'].mean().reindex(dow_order)
            
            fig = px.bar(
                x=dow_dist.index,
                y=dow_dist.values,
                title="Average Distance by Day",
                labels={'x': 'Day', 'y': 'Miles'}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Key insights
        st.markdown("---")
        st.subheader("ðŸ“Š Key Insights")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_weekly = weekly_miles.mean()
            st.info(f"**Weekly Mileage:** {avg_weekly:.1f} miles average")
        
        with col2:
            most_common_day = dow_counts.idxmax()
            st.info(f"**Most Common Day:** {most_common_day}")
        
        with col3:
            fastest_pace = running_data['pace_min_per_mile'].min()
            st.info(f"**Fastest Pace:** {fastest_pace:.2f} min/mile")
        
        with col4:
            longest_run = running_data['distance_miles'].max()
            st.info(f"**Longest Run:** {longest_run:.2f} miles")

# ============================================================================
# PAGE: PERFORMANCE PATTERNS (CLUSTERING)
# ============================================================================

elif page == "Performance Patterns":
    st.title("Performance Pattern Analysis")
    st.markdown("Discover what training patterns lead to your best running performances")
    st.markdown("---")
    
    running_data = filtered_data[filtered_data['sport_type'] == 'Run'].copy()
    
    if len(running_data) < 10:
        st.warning("Need at least 10 runs for meaningful pattern analysis.")
    else:
        # Calculate performance scores
        running_data['pace_percentile'] = running_data['pace_min_per_mile'].rank(pct=True)
        running_data['distance_percentile'] = running_data['distance_miles'].rank(pct=True)
        running_data['performance_score'] = (1 - running_data['pace_percentile']) + running_data['distance_percentile']
        
        threshold = running_data['performance_score'].quantile((100 - top_performance_pct) / 100)
        running_data['is_top_performance'] = (running_data['performance_score'] >= threshold).astype(int)
        
        # Show performance distribution
        st.subheader("Performance Score Distribution")
        fig = px.histogram(
            running_data,
            x='performance_score',
            color='is_top_performance',
            title=f"Top {top_performance_pct}% Performances Highlighted",
            labels={'performance_score': 'Performance Score', 'is_top_performance': 'Top Performance'},
            nbins=30
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Calculate training context
        @st.cache_data
        def calculate_training_context(running_df, all_df, window_days):
            features = []
            running_df = running_df.sort_values('start_date_local')
            
            for idx, run in running_df.iterrows():
                run_date = run['start_date_local']
                window_start = run_date - timedelta(days=window_days)
                
                prior_runs = running_df[(running_df['start_date_local'] >= window_start) & 
                                       (running_df['start_date_local'] < run_date)]
                prior_all = all_df[(all_df['start_date_local'] >= window_start) & 
                                  (all_df['start_date_local'] < run_date)]
                
                features.append({
                    'run_id': run['id'],
                    'run_date': run_date,
                    'prior_run_count': len(prior_runs),
                    'prior_total_miles': prior_runs['distance_miles'].sum() if len(prior_runs) > 0 else 0,
                    'prior_avg_pace': prior_runs['pace_min_per_mile'].mean() if len(prior_runs) > 0 else np.nan,
                    'prior_longest_run': prior_runs['distance_miles'].max() if len(prior_runs) > 0 else 0,
                    'prior_lifting_count': len(prior_all[prior_all['sport_type'] == 'WeightTraining']),
                    'prior_total_workouts': len(prior_all),
                    'days_since_last_run': (run_date - prior_runs['start_date_local'].max()).days if len(prior_runs) > 0 else window_days,
                    'day_of_week': run['day_of_week'],
                    'is_weekend': run['is_weekend'],
                    'time_of_day_numeric': run['hour'],
                    'performance_score': run['performance_score'],
                    'is_top_performance': run['is_top_performance'],
                    'actual_pace': run['pace_min_per_mile'],
                    'actual_distance': run['distance_miles']
                })
            
            return pd.DataFrame(features).dropna(subset=['prior_avg_pace'])
        
        with st.spinner("Analyzing training patterns..."):
            training_features = calculate_training_context(running_data, filtered_data, lookback_days)
        
        if len(training_features) < 10:
            st.warning("Not enough data with complete training context.")
        else:
            # Clustering
            cluster_features = [
                'prior_run_count', 'prior_total_miles', 'prior_longest_run',
                'prior_lifting_count', 'days_since_last_run',
                'day_of_week', 'is_weekend', 'time_of_day_numeric'
            ]
            
